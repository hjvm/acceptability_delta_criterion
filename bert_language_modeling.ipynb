{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from bert_training import training\n",
    "from copy import deepcopy\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import FillMaskPipeline, TextClassificationPipeline, pipeline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERT models.\n",
    "BERT_BASE = 'bert-base-uncased'\n",
    "BERT_LARGE = 'bert-large-uncased'\n",
    "BERT_LARGE_CASED = 'bert-large-cased'\n",
    "MODELS = [BERT_BASE, BERT_LARGE, BERT_LARGE_CASED]\n",
    "## Data of interest.\n",
    "DATA_FILE = Path('./data/li-adger_sentences.csv')\n",
    "OUT_DIR = Path('./output/bert_mlm_results_li-adger_sentences.csv')\n",
    "\n",
    "## Random seeds used to train BERT.\n",
    "RANDOM_SEEDS = [18, 11, 97, 7, 39, 40, 67, 5, 84, 72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dataset notes typo?                   id  \\\n",
      "0      LI   NaN   NaN  32.1.martin.1a.g.01   \n",
      "1      LI   NaN   NaN  32.1.martin.1a.g.02   \n",
      "2      LI   NaN   NaN  32.1.martin.1a.g.03   \n",
      "3      LI   NaN   NaN  32.1.martin.1a.g.04   \n",
      "4      LI   NaN   NaN  32.1.martin.1a.g.05   \n",
      "\n",
      "                                        sentence  sent_length  \n",
      "0              Kerry attempted to study physics.            7  \n",
      "1             Jimmy attempted to weave a basket.            8  \n",
      "2     Brittany attempted to touch the porcupine.            8  \n",
      "3  Frank attempted to eat a triple fudge sundae.           10  \n",
      "4                Kat attempted to keep her mail.            8  \n"
     ]
    }
   ],
   "source": [
    "## Load the .csv file with LI & Adger sentences into memory.\n",
    "sentences = pd.read_csv(DATA_FILE)\n",
    "print(sentences.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function to apply Masked Language Modeling pipeline to a Pandas DataFrame.\n",
    "def sentence_mlm_prob(sentence, sent_id, model, tokenizer):\n",
    "    logp_sentence = 0\n",
    "    unigram_prob = []\n",
    "    sent_tokenized = tokenizer.tokenize(sentence)\n",
    "    for i in range(1, len(sent_tokenized) + 1): # Need to offset because the tokenizer will\n",
    "        # Mask the tokens in order.               automatically pad the sequence with [CLS] and [SEP].\n",
    "        token = sent_tokenized[i - 1]\n",
    "        input_id = tokenizer.convert_tokens_to_ids([token])\n",
    "        \n",
    "        # Copy the list of tokens and replace one with <mask>.\n",
    "        masked_sent = sent_tokenized[:]\n",
    "        masked_sent[i - 1] = tokenizer.mask_token\n",
    "        \n",
    "        # Convert the list of tokens back into a coherent sentence.\n",
    "        inputs = tokenizer.convert_tokens_to_string(masked_sent)\n",
    "        #print(inputs)\n",
    "        \n",
    "        # Get the full sentence embedding for MLM prediction.\n",
    "        inputs = tokenizer(inputs, return_tensors=\"pt\") # return pytorch tensor\n",
    "        #print(inputs.input_ids)\n",
    "        \n",
    "        # Get model outputs with softmax applied.  \n",
    "        # Note: outputs will have shape batch_size x sequence_length x vocab_size.\n",
    "        outputs = model(**inputs, return_dict=True).logits.softmax(dim=2)\n",
    "        token_prob = outputs[0, i, input_id].detach().numpy()\n",
    "        \n",
    "        #print(f\"Probability of token {token}: {token_prob}\")\n",
    "        \n",
    "        # Aggregate.\n",
    "        logp_sentence += np.log(token_prob)[0]\n",
    "        unigram_prob.append({token:token_prob})\n",
    "    \n",
    "    # This return will create 2 new columns in the original dataframe.\n",
    "    #return pd.Series([logp_sentence, unigram_prob], index=[\"mlm_logprob\", \"unigram_mlm_logprob\"])\n",
    "    return {'id':sent_id,\n",
    "            'sentence':sentence, \n",
    "            'pseudoLogProb':logp_sentence,\n",
    "            'mlmUnigramProb':unigram_prob}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the MLM pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>notes</th>\n",
       "      <th>typo?</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>bert-large-cased_mlm</th>\n",
       "      <th>bert-large-cased_mlm_zscores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.01</td>\n",
       "      <td>Kerry attempted to study physics.</td>\n",
       "      <td>7</td>\n",
       "      <td>-26.039757</td>\n",
       "      <td>1.065650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.02</td>\n",
       "      <td>Jimmy attempted to weave a basket.</td>\n",
       "      <td>8</td>\n",
       "      <td>-30.894372</td>\n",
       "      <td>0.641492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.03</td>\n",
       "      <td>Brittany attempted to touch the porcupine.</td>\n",
       "      <td>8</td>\n",
       "      <td>-59.184504</td>\n",
       "      <td>-1.830278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.04</td>\n",
       "      <td>Frank attempted to eat a triple fudge sundae.</td>\n",
       "      <td>10</td>\n",
       "      <td>-35.032345</td>\n",
       "      <td>0.279948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.05</td>\n",
       "      <td>Kat attempted to keep her mail.</td>\n",
       "      <td>8</td>\n",
       "      <td>-40.031179</td>\n",
       "      <td>-0.156811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset notes typo?                   id  \\\n",
       "0      LI   NaN   NaN  32.1.martin.1a.g.01   \n",
       "1      LI   NaN   NaN  32.1.martin.1a.g.02   \n",
       "2      LI   NaN   NaN  32.1.martin.1a.g.03   \n",
       "3      LI   NaN   NaN  32.1.martin.1a.g.04   \n",
       "4      LI   NaN   NaN  32.1.martin.1a.g.05   \n",
       "\n",
       "                                        sentence  sent_length  \\\n",
       "0              Kerry attempted to study physics.            7   \n",
       "1             Jimmy attempted to weave a basket.            8   \n",
       "2     Brittany attempted to touch the porcupine.            8   \n",
       "3  Frank attempted to eat a triple fudge sundae.           10   \n",
       "4                Kat attempted to keep her mail.            8   \n",
       "\n",
       "   bert-large-cased_mlm  bert-large-cased_mlm_zscores  \n",
       "0            -26.039757                      1.065650  \n",
       "1            -30.894372                      0.641492  \n",
       "2            -59.184504                     -1.830278  \n",
       "3            -35.032345                      0.279948  \n",
       "4            -40.031179                     -0.156811  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing the MLM pipeline...\")\n",
    "## Instantiate the Masked Language Modelling (MLM) BERT.\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_LARGE_CASED)\n",
    "model = AutoModelForMaskedLM.from_pretrained(BERT_LARGE_CASED)\n",
    "\n",
    "# Disable gradient calculations for inference (no backpropagation).\n",
    "torch.no_grad()\n",
    "\n",
    "## Get MLM probability for the first few sentences in the sentences DataFrame.\n",
    "results = np.vectorize(sentence_mlm_prob)(sentences.sentence.head(), sentences.id.head(), model, tokenizer)\n",
    "results = pd.DataFrame(results.tolist())\n",
    "\n",
    "## Parse the results and calculate z-scores.\n",
    "new_data = sentences.merge(results[[\"id\", \"pseudoLogProb\"]], how=\"inner\", on=\"id\", validate=\"one_to_one\")\n",
    "new_data.rename({\"pseudoLogProb\":BERT_LARGE_CASED + \"_mlm\"}, axis=\"columns\", inplace=True)\n",
    "\n",
    "mlm_data = new_data[BERT_LARGE_CASED + \"_mlm\"]\n",
    "new_data[BERT_LARGE_CASED + \"_mlm_zscores\"] = (mlm_data - mlm_data.mean())/mlm_data.std(ddof=0)\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading bert-base-uncased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading bert-large-uncased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading bert-large-cased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>notes</th>\n",
       "      <th>typo?</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>bert-base-uncased_mlm</th>\n",
       "      <th>bert-base-uncased_mlm_zscores</th>\n",
       "      <th>bert-large-uncased_mlm</th>\n",
       "      <th>bert-large-uncased_mlm_zscores</th>\n",
       "      <th>bert-large-cased_mlm</th>\n",
       "      <th>bert-large-cased_mlm_zscores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.01</td>\n",
       "      <td>Kerry attempted to study physics.</td>\n",
       "      <td>7</td>\n",
       "      <td>-27.880027</td>\n",
       "      <td>0.325898</td>\n",
       "      <td>-23.415677</td>\n",
       "      <td>0.655122</td>\n",
       "      <td>-26.039757</td>\n",
       "      <td>0.371827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.02</td>\n",
       "      <td>Jimmy attempted to weave a basket.</td>\n",
       "      <td>8</td>\n",
       "      <td>-31.754557</td>\n",
       "      <td>0.047632</td>\n",
       "      <td>-32.266427</td>\n",
       "      <td>0.034538</td>\n",
       "      <td>-30.894372</td>\n",
       "      <td>0.020289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.03</td>\n",
       "      <td>Brittany attempted to touch the porcupine.</td>\n",
       "      <td>8</td>\n",
       "      <td>-51.947159</td>\n",
       "      <td>-1.402585</td>\n",
       "      <td>-46.151353</td>\n",
       "      <td>-0.939024</td>\n",
       "      <td>-59.184504</td>\n",
       "      <td>-2.028288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.04</td>\n",
       "      <td>Frank attempted to eat a triple fudge sundae.</td>\n",
       "      <td>10</td>\n",
       "      <td>-51.125628</td>\n",
       "      <td>-1.343583</td>\n",
       "      <td>-44.627996</td>\n",
       "      <td>-0.832212</td>\n",
       "      <td>-35.032345</td>\n",
       "      <td>-0.279355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.05</td>\n",
       "      <td>Kat attempted to keep her mail.</td>\n",
       "      <td>8</td>\n",
       "      <td>-43.211186</td>\n",
       "      <td>-0.775174</td>\n",
       "      <td>-34.555760</td>\n",
       "      <td>-0.125982</td>\n",
       "      <td>-40.031179</td>\n",
       "      <td>-0.641336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset notes typo?                   id  \\\n",
       "0      LI   NaN   NaN  32.1.martin.1a.g.01   \n",
       "1      LI   NaN   NaN  32.1.martin.1a.g.02   \n",
       "2      LI   NaN   NaN  32.1.martin.1a.g.03   \n",
       "3      LI   NaN   NaN  32.1.martin.1a.g.04   \n",
       "4      LI   NaN   NaN  32.1.martin.1a.g.05   \n",
       "\n",
       "                                        sentence  sent_length  \\\n",
       "0              Kerry attempted to study physics.            7   \n",
       "1             Jimmy attempted to weave a basket.            8   \n",
       "2     Brittany attempted to touch the porcupine.            8   \n",
       "3  Frank attempted to eat a triple fudge sundae.           10   \n",
       "4                Kat attempted to keep her mail.            8   \n",
       "\n",
       "   bert-base-uncased_mlm  bert-base-uncased_mlm_zscores  \\\n",
       "0             -27.880027                       0.325898   \n",
       "1             -31.754557                       0.047632   \n",
       "2             -51.947159                      -1.402585   \n",
       "3             -51.125628                      -1.343583   \n",
       "4             -43.211186                      -0.775174   \n",
       "\n",
       "   bert-large-uncased_mlm  bert-large-uncased_mlm_zscores  \\\n",
       "0              -23.415677                        0.655122   \n",
       "1              -32.266427                        0.034538   \n",
       "2              -46.151353                       -0.939024   \n",
       "3              -44.627996                       -0.832212   \n",
       "4              -34.555760                       -0.125982   \n",
       "\n",
       "   bert-large-cased_mlm  bert-large-cased_mlm_zscores  \n",
       "0            -26.039757                      0.371827  \n",
       "1            -30.894372                      0.020289  \n",
       "2            -59.184504                     -2.028288  \n",
       "3            -35.032345                     -0.279355  \n",
       "4            -40.031179                     -0.641336  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply the pipeline to all three BERT models.\n",
    "for bert in MODELS:\n",
    "    print(\"Now loading {}...\".format(bert))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(bert)\n",
    "    \n",
    "    # Disable gradient calculations for inference (no backpropagation).\n",
    "    torch.no_grad()\n",
    "\n",
    "    ## Get MLM probability for each sentence in the sentences DataFrame.\n",
    "    results = np.vectorize(sentence_mlm_prob)(sentences.sentence, sentences.id, model, tokenizer)\n",
    "    results = pd.DataFrame(results.tolist())\n",
    "\n",
    "    ## Parse the results and calculate z-scores.\n",
    "    sentences = sentences.merge(results[[\"id\", \"pseudoLogProb\"]], how=\"left\", on=\"id\", validate=\"one_to_one\")\n",
    "    sentences.rename({\"pseudoLogProb\":bert + \"_mlm\"}, axis=\"columns\", inplace=True)\n",
    "\n",
    "    new_data = sentences[bert + \"_mlm\"] # just to keep the following line short...\n",
    "    sentences[bert + \"_mlm_zscores\"] = (new_data - new_data.mean())/new_data.std(ddof=0)\n",
    "\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.to_csv(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>notes</th>\n",
       "      <th>typo?</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>bert-base-uncased_mlm</th>\n",
       "      <th>bert-base-uncased_mlm_zscores</th>\n",
       "      <th>bert-large-uncased_mlm</th>\n",
       "      <th>bert-large-uncased_mlm_zscores</th>\n",
       "      <th>bert-large-cased_mlm</th>\n",
       "      <th>bert-large-cased_mlm_zscores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.01</td>\n",
       "      <td>Kerry attempted to study physics.</td>\n",
       "      <td>7</td>\n",
       "      <td>-27.880027</td>\n",
       "      <td>0.325898</td>\n",
       "      <td>-23.415677</td>\n",
       "      <td>0.655122</td>\n",
       "      <td>-26.039757</td>\n",
       "      <td>0.371827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.02</td>\n",
       "      <td>Jimmy attempted to weave a basket.</td>\n",
       "      <td>8</td>\n",
       "      <td>-31.754557</td>\n",
       "      <td>0.047632</td>\n",
       "      <td>-32.266427</td>\n",
       "      <td>0.034538</td>\n",
       "      <td>-30.894372</td>\n",
       "      <td>0.020289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.03</td>\n",
       "      <td>Brittany attempted to touch the porcupine.</td>\n",
       "      <td>8</td>\n",
       "      <td>-51.947159</td>\n",
       "      <td>-1.402585</td>\n",
       "      <td>-46.151353</td>\n",
       "      <td>-0.939024</td>\n",
       "      <td>-59.184504</td>\n",
       "      <td>-2.028288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.04</td>\n",
       "      <td>Frank attempted to eat a triple fudge sundae.</td>\n",
       "      <td>10</td>\n",
       "      <td>-51.125628</td>\n",
       "      <td>-1.343583</td>\n",
       "      <td>-44.627996</td>\n",
       "      <td>-0.832212</td>\n",
       "      <td>-35.032345</td>\n",
       "      <td>-0.279355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.05</td>\n",
       "      <td>Kat attempted to keep her mail.</td>\n",
       "      <td>8</td>\n",
       "      <td>-43.211186</td>\n",
       "      <td>-0.775174</td>\n",
       "      <td>-34.555760</td>\n",
       "      <td>-0.125982</td>\n",
       "      <td>-40.031179</td>\n",
       "      <td>-0.641336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>Adger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch9.84-85.g.04</td>\n",
       "      <td>I wondered how Lewis survived.</td>\n",
       "      <td>7</td>\n",
       "      <td>-15.926197</td>\n",
       "      <td>1.184412</td>\n",
       "      <td>-19.627203</td>\n",
       "      <td>0.920756</td>\n",
       "      <td>-19.455108</td>\n",
       "      <td>0.848642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>Adger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch9.84-85.g.05</td>\n",
       "      <td>I wondered where Sophie lived.</td>\n",
       "      <td>7</td>\n",
       "      <td>-14.682488</td>\n",
       "      <td>1.273734</td>\n",
       "      <td>-22.011065</td>\n",
       "      <td>0.753608</td>\n",
       "      <td>-19.165803</td>\n",
       "      <td>0.869591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>Adger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch9.84-85.g.06</td>\n",
       "      <td>I wondered what Dan cooked for breakfast.</td>\n",
       "      <td>9</td>\n",
       "      <td>-23.778206</td>\n",
       "      <td>0.620487</td>\n",
       "      <td>-25.143076</td>\n",
       "      <td>0.534002</td>\n",
       "      <td>-19.656588</td>\n",
       "      <td>0.834052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Adger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch9.84-85.g.07</td>\n",
       "      <td>I wondered who Lisa married.</td>\n",
       "      <td>7</td>\n",
       "      <td>-25.661793</td>\n",
       "      <td>0.485209</td>\n",
       "      <td>-27.157065</td>\n",
       "      <td>0.392788</td>\n",
       "      <td>-23.216581</td>\n",
       "      <td>0.576262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Adger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch9.84-85.g.08</td>\n",
       "      <td>I wondered where Katie went to school.</td>\n",
       "      <td>9</td>\n",
       "      <td>-11.991900</td>\n",
       "      <td>1.466970</td>\n",
       "      <td>-11.190507</td>\n",
       "      <td>1.512308</td>\n",
       "      <td>-11.295845</td>\n",
       "      <td>1.439479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4178 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset notes typo?                   id  \\\n",
       "0         LI   NaN   NaN  32.1.martin.1a.g.01   \n",
       "1         LI   NaN   NaN  32.1.martin.1a.g.02   \n",
       "2         LI   NaN   NaN  32.1.martin.1a.g.03   \n",
       "3         LI   NaN   NaN  32.1.martin.1a.g.04   \n",
       "4         LI   NaN   NaN  32.1.martin.1a.g.05   \n",
       "...      ...   ...   ...                  ...   \n",
       "4173   Adger   NaN   NaN       ch9.84-85.g.04   \n",
       "4174   Adger   NaN   NaN       ch9.84-85.g.05   \n",
       "4175   Adger   NaN   NaN       ch9.84-85.g.06   \n",
       "4176   Adger   NaN   NaN       ch9.84-85.g.07   \n",
       "4177   Adger   NaN   NaN       ch9.84-85.g.08   \n",
       "\n",
       "                                           sentence  sent_length  \\\n",
       "0                 Kerry attempted to study physics.            7   \n",
       "1                Jimmy attempted to weave a basket.            8   \n",
       "2        Brittany attempted to touch the porcupine.            8   \n",
       "3     Frank attempted to eat a triple fudge sundae.           10   \n",
       "4                   Kat attempted to keep her mail.            8   \n",
       "...                                             ...          ...   \n",
       "4173                 I wondered how Lewis survived.            7   \n",
       "4174                 I wondered where Sophie lived.            7   \n",
       "4175      I wondered what Dan cooked for breakfast.            9   \n",
       "4176                   I wondered who Lisa married.            7   \n",
       "4177         I wondered where Katie went to school.            9   \n",
       "\n",
       "      bert-base-uncased_mlm  bert-base-uncased_mlm_zscores  \\\n",
       "0                -27.880027                       0.325898   \n",
       "1                -31.754557                       0.047632   \n",
       "2                -51.947159                      -1.402585   \n",
       "3                -51.125628                      -1.343583   \n",
       "4                -43.211186                      -0.775174   \n",
       "...                     ...                            ...   \n",
       "4173             -15.926197                       1.184412   \n",
       "4174             -14.682488                       1.273734   \n",
       "4175             -23.778206                       0.620487   \n",
       "4176             -25.661793                       0.485209   \n",
       "4177             -11.991900                       1.466970   \n",
       "\n",
       "      bert-large-uncased_mlm  bert-large-uncased_mlm_zscores  \\\n",
       "0                 -23.415677                        0.655122   \n",
       "1                 -32.266427                        0.034538   \n",
       "2                 -46.151353                       -0.939024   \n",
       "3                 -44.627996                       -0.832212   \n",
       "4                 -34.555760                       -0.125982   \n",
       "...                      ...                             ...   \n",
       "4173              -19.627203                        0.920756   \n",
       "4174              -22.011065                        0.753608   \n",
       "4175              -25.143076                        0.534002   \n",
       "4176              -27.157065                        0.392788   \n",
       "4177              -11.190507                        1.512308   \n",
       "\n",
       "      bert-large-cased_mlm  bert-large-cased_mlm_zscores  \n",
       "0               -26.039757                      0.371827  \n",
       "1               -30.894372                      0.020289  \n",
       "2               -59.184504                     -2.028288  \n",
       "3               -35.032345                     -0.279355  \n",
       "4               -40.031179                     -0.641336  \n",
       "...                    ...                           ...  \n",
       "4173            -19.455108                      0.848642  \n",
       "4174            -19.165803                      0.869591  \n",
       "4175            -19.656588                      0.834052  \n",
       "4176            -23.216581                      0.576262  \n",
       "4177            -11.295845                      1.439479  \n",
       "\n",
       "[4178 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>notes</th>\n",
       "      <th>typo?</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sent_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.01</td>\n",
       "      <td>Kerry attempted to study physics.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.02</td>\n",
       "      <td>Jimmy attempted to weave a basket.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.03</td>\n",
       "      <td>Brittany attempted to touch the porcupine.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.04</td>\n",
       "      <td>Frank attempted to eat a triple fudge sundae.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.1.martin.1a.g.05</td>\n",
       "      <td>Kat attempted to keep her mail.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>Adger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch9.84-85.g.04</td>\n",
       "      <td>I wondered how Lewis survived.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>Adger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch9.84-85.g.05</td>\n",
       "      <td>I wondered where Sophie lived.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>Adger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch9.84-85.g.06</td>\n",
       "      <td>I wondered what Dan cooked for breakfast.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Adger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch9.84-85.g.07</td>\n",
       "      <td>I wondered who Lisa married.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Adger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch9.84-85.g.08</td>\n",
       "      <td>I wondered where Katie went to school.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4178 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset notes typo?                   id  \\\n",
       "0         LI   NaN   NaN  32.1.martin.1a.g.01   \n",
       "1         LI   NaN   NaN  32.1.martin.1a.g.02   \n",
       "2         LI   NaN   NaN  32.1.martin.1a.g.03   \n",
       "3         LI   NaN   NaN  32.1.martin.1a.g.04   \n",
       "4         LI   NaN   NaN  32.1.martin.1a.g.05   \n",
       "...      ...   ...   ...                  ...   \n",
       "4173   Adger   NaN   NaN       ch9.84-85.g.04   \n",
       "4174   Adger   NaN   NaN       ch9.84-85.g.05   \n",
       "4175   Adger   NaN   NaN       ch9.84-85.g.06   \n",
       "4176   Adger   NaN   NaN       ch9.84-85.g.07   \n",
       "4177   Adger   NaN   NaN       ch9.84-85.g.08   \n",
       "\n",
       "                                           sentence  sent_length  \n",
       "0                 Kerry attempted to study physics.            7  \n",
       "1                Jimmy attempted to weave a basket.            8  \n",
       "2        Brittany attempted to touch the porcupine.            8  \n",
       "3     Frank attempted to eat a triple fudge sundae.           10  \n",
       "4                   Kat attempted to keep her mail.            8  \n",
       "...                                             ...          ...  \n",
       "4173                 I wondered how Lewis survived.            7  \n",
       "4174                 I wondered where Sophie lived.            7  \n",
       "4175      I wondered what Dan cooked for breakfast.            9  \n",
       "4176                   I wondered who Lisa married.            7  \n",
       "4177         I wondered where Katie went to school.            9  \n",
       "\n",
       "[4178 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
